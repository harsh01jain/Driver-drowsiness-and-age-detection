{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7923cda-cf4c-4c6f-ade3-76a58edb5c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Harsh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Tensorlfow Version:  2.15.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Activation, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import itertools\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"Tensorlfow Version: \", tf.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SEED = 42   # set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b542c490-d981-498f-8206-e048b0dfa885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train path: C:\\Users\\Harsh\\Downloads\\data_science01\\dl_projects\\task 3\\DATA\\drowsiness\\train\n"
     ]
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "trainpath = os.path.abspath(os.path.join(current_dir, '..', 'DATA', 'drowsiness','train'))\n",
    "\n",
    "print(f\"Train path: {trainpath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5eafa15-1fd1-41cd-b833-bce22d909617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1452\n"
     ]
    }
   ],
   "source": [
    "## determine the total number of image paths in training, validation,\n",
    "# and testing directories\n",
    "totalTrain = len(list(paths.list_images(trainpath)))\n",
    "# totalTest = len(list(paths.list_images(testpath)))\n",
    "print(totalTrain)\n",
    "# print(totalTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b916c1f-9c03-42af-ac03-383b3e81a7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2db256d8a6f54078b4bda964a5adb253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize the data and labels\n",
    "print(\"[INFO] loading images...\")\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# grab the image paths and randomly shuffle them\n",
    "imagePaths = sorted(list(paths.list_images(trainpath)))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)\n",
    "\n",
    "# progress bar \n",
    "with tqdm(total=len(imagePaths)) as pbar:\n",
    "    \n",
    "    # loop over the input images\n",
    "    for idx, imagePath in enumerate(imagePaths):\n",
    "        # load the image, pre-process it, and store it in the data list\n",
    "        image = cv2.imread(imagePath)\n",
    "        image = cv2.resize(image, (64, 64))\n",
    "        image = img_to_array(image)\n",
    "        data.append(image)\n",
    "\n",
    "        # extract the class label from the image path and update the\n",
    "        # labels list\n",
    "        label = imagePath.split(os.path.sep)[-2]\n",
    "\n",
    "        if label == \"awake\":\n",
    "            label = 0\n",
    "        elif label == \"sleeping\":\n",
    "            label = 1\n",
    "        # print(\"pr: \", label)\t\n",
    "        labels.append(label)\n",
    "        \n",
    "        # update the progressbar\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dd761de-ee91-46b7-a5e3-d9a1dede46e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7af33577-b450-45d0-92a4-52b1bed6712b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 93., 103., 143.],\n",
       "        [ 97., 105., 145.],\n",
       "        [ 97., 105., 146.],\n",
       "        ...,\n",
       "        [ 75.,  79.,  97.],\n",
       "        [ 53.,  54.,  66.],\n",
       "        [ 35.,  38.,  44.]],\n",
       "\n",
       "       [[ 94., 104., 144.],\n",
       "        [ 97., 105., 145.],\n",
       "        [ 98., 106., 146.],\n",
       "        ...,\n",
       "        [ 81.,  85., 103.],\n",
       "        [ 58.,  60.,  73.],\n",
       "        [ 35.,  38.,  44.]],\n",
       "\n",
       "       [[ 92., 102., 142.],\n",
       "        [ 95., 103., 143.],\n",
       "        [ 97., 105., 145.],\n",
       "        ...,\n",
       "        [ 85.,  89., 109.],\n",
       "        [ 61.,  65.,  77.],\n",
       "        [ 35.,  36.,  45.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[109., 126., 165.],\n",
       "        [112., 128., 167.],\n",
       "        [114., 131., 170.],\n",
       "        ...,\n",
       "        [141., 150., 170.],\n",
       "        [148., 158., 175.],\n",
       "        [150., 159., 173.]],\n",
       "\n",
       "       [[109., 126., 165.],\n",
       "        [111., 128., 167.],\n",
       "        [111., 129., 168.],\n",
       "        ...,\n",
       "        [139., 148., 169.],\n",
       "        [148., 158., 175.],\n",
       "        [149., 158., 172.]],\n",
       "\n",
       "       [[109., 126., 166.],\n",
       "        [109., 126., 166.],\n",
       "        [108., 125., 166.],\n",
       "        ...,\n",
       "        [140., 149., 170.],\n",
       "        [147., 157., 174.],\n",
       "        [148., 157., 171.]]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67edf662-262d-42b5-a19e-5044ecf6c070",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebb20579-9446-4263-866b-d488422a644d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(data,labels, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13394666-0df0-4fbf-9e14-7cc264cf4f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1089, 64, 64, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2c474cf-10b6-4b0e-b931-b4d3ace54c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1089,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e78f8e53-9d67-4d85-9fef-28e10c6fd698",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = to_categorical(trainY, num_classes=2)\n",
    "testY = to_categorical(testY, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dce799f5-4da2-4bae-a944-d5baa5f1f6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=30, \n",
    "                         width_shift_range=0.1, \n",
    "                         height_shift_range=0.1, \n",
    "                         shear_range=0.2, \n",
    "                         zoom_range=0.2, \n",
    "                         horizontal_flip=True, \n",
    "                         fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13edfd49-cb8b-421a-9b3a-134edfb17e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes):\n",
    "        # initialize the model\n",
    "        model = Sequential()\n",
    "        inputShape = (height, width, depth)  # (h, h, channel)\n",
    "\n",
    "        # if we are using \"channels first\", update the input shape\n",
    "        if K.image_data_format() == \"channels_first\":\n",
    "            inputShape = (depth, height, width)\n",
    "\n",
    "        # first set of CONV => LeakyReLU => POOL layers\n",
    "        model.add(Conv2D(100, (5, 5), padding=\"same\", input_shape=inputShape))\n",
    "        model.add(LeakyReLU(alpha=0.1))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "        # second set of CONV => LeakyReLU => POOL layers\n",
    "        model.add(Conv2D(200, (5, 5), padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.1))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "        # third set of CONV => LeakyReLU => POOL layers\n",
    "        model.add(Conv2D(400, (5, 5), padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.1))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "        # first (and only) set of FC => LeakyReLU layers\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(800))\n",
    "        model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "        # softmax classifier\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "        # return the constructed network architecture\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "befd9a31-0c32-4f33-b2f0-960f6fb5de22",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "INIT_LR = 1e-3\n",
    "BS = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2dfc154-9aef-4f26-b630-63ec55059c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "WARNING:tensorflow:From C:\\Users\\Harsh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Harsh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "[INFO] model complied...\n"
     ]
    }
   ],
   "source": [
    "# initialize the model\n",
    "print(\"[INFO] compiling model...\")\n",
    "model = LeNet.build(width=64, height=64, depth=3, classes=2)\n",
    "opt = Adam(learning_rate=INIT_LR)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "print(\"[INFO] model complied...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dcf035-26dd-46dc-b4b0-e0af3bf59a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From C:\\Users\\Harsh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Harsh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "17/17 [==============================] - 21s 1s/step - loss: 2.7082 - accuracy: 0.4898 - val_loss: 0.7181 - val_accuracy: 0.4353\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.7215 - accuracy: 0.5073 - val_loss: 0.6898 - val_accuracy: 0.5124\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.6876 - accuracy: 0.5415 - val_loss: 0.7068 - val_accuracy: 0.5014\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.6767 - accuracy: 0.6498 - val_loss: 0.6341 - val_accuracy: 0.6529\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 17s 1s/step - loss: 0.6247 - accuracy: 0.6810 - val_loss: 0.5534 - val_accuracy: 0.7658\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.5376 - accuracy: 0.7580 - val_loss: 0.4216 - val_accuracy: 0.8292\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.5219 - accuracy: 0.7639 - val_loss: 0.3561 - val_accuracy: 0.8650\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 17s 1s/step - loss: 0.4060 - accuracy: 0.8068 - val_loss: 0.2499 - val_accuracy: 0.8898\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 17s 1s/step - loss: 0.2817 - accuracy: 0.8868 - val_loss: 0.1585 - val_accuracy: 0.9311\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.2534 - accuracy: 0.8976 - val_loss: 0.1662 - val_accuracy: 0.9394\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 17s 1s/step - loss: 0.4133 - accuracy: 0.8546 - val_loss: 0.2389 - val_accuracy: 0.8843\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 17s 1s/step - loss: 0.2993 - accuracy: 0.8820 - val_loss: 0.2272 - val_accuracy: 0.8981\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 17s 1s/step - loss: 0.1883 - accuracy: 0.9307 - val_loss: 0.1054 - val_accuracy: 0.9532\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.2246 - accuracy: 0.9268 - val_loss: 0.1126 - val_accuracy: 0.9559\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.2050 - accuracy: 0.9278 - val_loss: 0.0958 - val_accuracy: 0.9587\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.1907 - accuracy: 0.9259 - val_loss: 0.1246 - val_accuracy: 0.9614\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.1775 - accuracy: 0.9385 - val_loss: 0.1159 - val_accuracy: 0.9587\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 17s 992ms/step - loss: 0.1713 - accuracy: 0.9346 - val_loss: 0.0659 - val_accuracy: 0.9725\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 17s 1s/step - loss: 0.1721 - accuracy: 0.9385 - val_loss: 0.1006 - val_accuracy: 0.9642\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 17s 999ms/step - loss: 0.1410 - accuracy: 0.9454 - val_loss: 0.0574 - val_accuracy: 0.9807\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.1383 - accuracy: 0.9424 - val_loss: 0.0838 - val_accuracy: 0.9725\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 17s 1s/step - loss: 0.1289 - accuracy: 0.9590 - val_loss: 0.0607 - val_accuracy: 0.9780\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.1540 - accuracy: 0.9395 - val_loss: 0.0780 - val_accuracy: 0.9725\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 17s 1s/step - loss: 0.1797 - accuracy: 0.9337 - val_loss: 0.1005 - val_accuracy: 0.9587\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 17s 1s/step - loss: 0.1709 - accuracy: 0.9473 - val_loss: 0.0820 - val_accuracy: 0.9725\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 17s 1s/step - loss: 0.1112 - accuracy: 0.9659 - val_loss: 0.0757 - val_accuracy: 0.9725\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.0998 - accuracy: 0.9600 - val_loss: 0.0415 - val_accuracy: 0.9862\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 17s 1s/step - loss: 0.0864 - accuracy: 0.9756 - val_loss: 0.0434 - val_accuracy: 0.9835\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.0910 - accuracy: 0.9678 - val_loss: 0.0424 - val_accuracy: 0.9862\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.0780 - accuracy: 0.9707 - val_loss: 0.0417 - val_accuracy: 0.9862\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 17s 1s/step - loss: 0.0700 - accuracy: 0.9717 - val_loss: 0.0401 - val_accuracy: 0.9835\n",
      "Epoch 32/50\n"
     ]
    }
   ],
   "source": [
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "H = model.fit(x=aug.flow(trainX, trainY, batch_size=BS),\n",
    "              validation_data=(testX, testY), \n",
    "              steps_per_epoch=len(trainX) // BS,\n",
    "              epochs=EPOCHS, \n",
    "              verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2509dbb-5f63-45e3-8c85-c7265c923703",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"driver_detection_50_epochs.model\",save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcf4f23-cfdb-41f3-989a-690adde67c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acc(H, N, plotPath=None): \n",
    "\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "    plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "    plt.title(\"Training Accuracy\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "   \n",
    "\n",
    "def plot_loss(H, N, plotPath=None):\n",
    "    \n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "\n",
    "    plt.title(\"Training Loss\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend(loc=\"lower left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6dd8b2-0434-48b3-8406-4b04e242a159",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acc(H,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac639467-8875-4794-b3a3-964f86a54411",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(H,50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
